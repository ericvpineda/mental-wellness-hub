{
  "version": 3,
  "sources": ["../../../../src/cli/lib/indexes.ts"],
  "sourcesContent": ["import chalk from \"chalk\";\nimport path from \"path\";\nimport { bundleSchema } from \"../../bundler/index.js\";\nimport { version } from \"../version.js\";\nimport {\n  Context,\n  changeSpinner,\n  logFailure,\n  logFinishedStep,\n  logError,\n} from \"../../bundler/context.js\";\nimport {\n  poll,\n  logAndHandleFetchError,\n  deploymentFetch,\n  fetchDeprecationCheckWarning,\n} from \"./utils.js\";\n\ntype IndexMetadata = {\n  table: string;\n  name: string;\n  fields:\n    | string[]\n    | {\n        searchField: string;\n        filterFields: string[];\n      };\n  backfill: {\n    state: \"in_progress\" | \"done\";\n  };\n};\n\ntype SchemaState =\n  | { state: \"pending\" }\n  | { state: \"validated\" }\n  | { state: \"active\" }\n  | { state: \"overwritten\" }\n  | { state: \"failed\"; error: string; tableName?: string };\n\ntype SchemaStateResponse = {\n  indexes: IndexMetadata[];\n  schemaState: SchemaState;\n};\ntype PrepareSchemaResponse = {\n  added: IndexMetadata[];\n  dropped: IndexMetadata[];\n  schemaId: string;\n};\n\nexport async function pushSchema(\n  ctx: Context,\n  origin: string,\n  adminKey: string,\n  schemaDir: string,\n  dryRun: boolean,\n): Promise<{ schemaId?: string; schemaState?: SchemaState }> {\n  if (!ctx.fs.exists(path.resolve(schemaDir, \"schema.ts\"))) {\n    // Don't do anything.\n    return {};\n  }\n  const bundles = await bundleSchema(ctx, schemaDir);\n\n  changeSpinner(ctx, \"Checking for index or schema changes...\");\n\n  let data: PrepareSchemaResponse;\n  const fetch = deploymentFetch(origin);\n  try {\n    const res = await fetch(\"/api/prepare_schema\", {\n      method: \"POST\",\n      headers: {\n        \"Convex-Client\": `npm-cli-${version}`,\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        bundle: bundles[0],\n        adminKey,\n        dryRun,\n      }),\n    });\n    fetchDeprecationCheckWarning(ctx, res);\n    data = await res.json();\n  } catch (err: unknown) {\n    logFailure(ctx, `Error: Unable to run schema validation on ${origin}`);\n    return await logAndHandleFetchError(ctx, err);\n  }\n\n  const schemaId = data.schemaId;\n\n  changeSpinner(\n    ctx,\n    \"Backfilling indexes and checking that documents match your schema...\",\n  );\n  const schemaState = await waitForReadySchema(ctx, origin, adminKey, schemaId);\n  logIndexChanges(ctx, data, dryRun);\n  return { schemaId, schemaState };\n}\n\n/// Wait for indexes to build and schema to be validated.\nasync function waitForReadySchema(\n  ctx: Context,\n  origin: string,\n  adminKey: string,\n  schemaId: string,\n): Promise<SchemaState> {\n  const path = `api/schema_state/${schemaId}`;\n  const depFetch = deploymentFetch(origin);\n  const fetch = async () => {\n    try {\n      const resp = await depFetch(path, {\n        headers: {\n          Authorization: `Convex ${adminKey}`,\n          \"Convex-Client\": `npm-cli-${version}`,\n          \"Content-Type\": \"application/json\",\n        },\n      });\n      const data: SchemaStateResponse = await resp.json();\n      return data;\n    } catch (err: unknown) {\n      logFailure(\n        ctx,\n        `Error: Unable to build indexes and run schema validation on ${origin}`,\n      );\n      return await logAndHandleFetchError(ctx, err);\n    }\n  };\n  const validate = (data: SchemaStateResponse) =>\n    data.indexes.every((index) => index.backfill.state === \"done\") &&\n    data.schemaState.state !== \"pending\";\n  const data = await poll(fetch, validate);\n  switch (data.schemaState.state) {\n    case \"failed\":\n      // Schema validation failed. This could be either because the data\n      // is bad or the schema is wrong. Classify this as a filesystem error\n      // because adjusting `schema.ts` is the most normal next step.\n      logFailure(ctx, \"Schema validation failed\");\n      logError(ctx, chalk.red(`${data.schemaState.error}`));\n      return await ctx.crash(1, {\n        \"invalid filesystem or db data\": data.schemaState.tableName ?? null,\n      });\n\n    case \"overwritten\":\n      logFailure(ctx, `Schema was overwritten by another push.`);\n      return await ctx.crash(1, \"fatal\");\n    case \"validated\":\n      logFinishedStep(ctx, \"Schema validation complete.\");\n      break;\n    case \"active\":\n      break;\n  }\n  return data.schemaState;\n}\n\nfunction logIndexChanges(\n  ctx: Context,\n  indexes: {\n    added: IndexMetadata[];\n    dropped: IndexMetadata[];\n  },\n  dryRun: boolean,\n) {\n  if (indexes.dropped.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.dropped) {\n      indexDiff += `  [-] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      ctx,\n      `${dryRun ? \"Would delete\" : \"Deleted\"} table indexes:\\n${indexDiff}`,\n    );\n  }\n  if (indexes.added.length > 0) {\n    let indexDiff = \"\";\n    for (const index of indexes.added) {\n      indexDiff += `  [+] ${stringifyIndex(index)}\\n`;\n    }\n    // strip last new line\n    indexDiff = indexDiff.slice(0, -1);\n    logFinishedStep(\n      ctx,\n      `${dryRun ? \"Would add\" : \"Added\"} table indexes:\\n${indexDiff}`,\n    );\n  }\n}\n\nfunction stringifyIndex(index: IndexMetadata) {\n  return `${index.table}.${index.name} ${JSON.stringify(index.fields)}`;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAAkB;AAClB,kBAAiB;AACjB,qBAA6B;AAC7B,qBAAwB;AACxB,qBAMO;AACP,mBAKO;AAiCP,eAAsB,WACpB,KACA,QACA,UACA,WACA,QAC2D;AAC3D,MAAI,CAAC,IAAI,GAAG,OAAO,YAAAA,QAAK,QAAQ,WAAW,WAAW,CAAC,GAAG;AAExD,WAAO,CAAC;AAAA,EACV;AACA,QAAM,UAAU,UAAM,6BAAa,KAAK,SAAS;AAEjD,oCAAc,KAAK,yCAAyC;AAE5D,MAAI;AACJ,QAAM,YAAQ,8BAAgB,MAAM;AACpC,MAAI;AACF,UAAM,MAAM,MAAM,MAAM,uBAAuB;AAAA,MAC7C,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,iBAAiB,WAAW;AAAA,QAC5B,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,QAAQ,QAAQ,CAAC;AAAA,QACjB;AAAA,QACA;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AACD,mDAA6B,KAAK,GAAG;AACrC,WAAO,MAAM,IAAI,KAAK;AAAA,EACxB,SAAS,KAAP;AACA,mCAAW,KAAK,6CAA6C,QAAQ;AACrE,WAAO,UAAM,qCAAuB,KAAK,GAAG;AAAA,EAC9C;AAEA,QAAM,WAAW,KAAK;AAEtB;AAAA,IACE;AAAA,IACA;AAAA,EACF;AACA,QAAM,cAAc,MAAM,mBAAmB,KAAK,QAAQ,UAAU,QAAQ;AAC5E,kBAAgB,KAAK,MAAM,MAAM;AACjC,SAAO,EAAE,UAAU,YAAY;AACjC;AAGA,eAAe,mBACb,KACA,QACA,UACA,UACsB;AACtB,QAAMA,QAAO,oBAAoB;AACjC,QAAM,eAAW,8BAAgB,MAAM;AACvC,QAAM,QAAQ,YAAY;AACxB,QAAI;AACF,YAAM,OAAO,MAAM,SAASA,OAAM;AAAA,QAChC,SAAS;AAAA,UACP,eAAe,UAAU;AAAA,UACzB,iBAAiB,WAAW;AAAA,UAC5B,gBAAgB;AAAA,QAClB;AAAA,MACF,CAAC;AACD,YAAMC,QAA4B,MAAM,KAAK,KAAK;AAClD,aAAOA;AAAA,IACT,SAAS,KAAP;AACA;AAAA,QACE;AAAA,QACA,+DAA+D;AAAA,MACjE;AACA,aAAO,UAAM,qCAAuB,KAAK,GAAG;AAAA,IAC9C;AAAA,EACF;AACA,QAAM,WAAW,CAACA,UAChBA,MAAK,QAAQ,MAAM,CAAC,UAAU,MAAM,SAAS,UAAU,MAAM,KAC7DA,MAAK,YAAY,UAAU;AAC7B,QAAM,OAAO,UAAM,mBAAK,OAAO,QAAQ;AACvC,UAAQ,KAAK,YAAY,OAAO;AAAA,IAC9B,KAAK;AAIH,qCAAW,KAAK,0BAA0B;AAC1C,mCAAS,KAAK,aAAAC,QAAM,IAAI,GAAG,KAAK,YAAY,OAAO,CAAC;AACpD,aAAO,MAAM,IAAI,MAAM,GAAG;AAAA,QACxB,iCAAiC,KAAK,YAAY,aAAa;AAAA,MACjE,CAAC;AAAA,IAEH,KAAK;AACH,qCAAW,KAAK,yCAAyC;AACzD,aAAO,MAAM,IAAI,MAAM,GAAG,OAAO;AAAA,IACnC,KAAK;AACH,0CAAgB,KAAK,6BAA6B;AAClD;AAAA,IACF,KAAK;AACH;AAAA,EACJ;AACA,SAAO,KAAK;AACd;AAEA,SAAS,gBACP,KACA,SAIA,QACA;AACA,MAAI,QAAQ,QAAQ,SAAS,GAAG;AAC9B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,SAAS;AACnC,mBAAa,SAAS,eAAe,KAAK;AAAA;AAAA,IAC5C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE;AAAA,MACA,GAAG,SAAS,iBAAiB;AAAA,EAA6B;AAAA,IAC5D;AAAA,EACF;AACA,MAAI,QAAQ,MAAM,SAAS,GAAG;AAC5B,QAAI,YAAY;AAChB,eAAW,SAAS,QAAQ,OAAO;AACjC,mBAAa,SAAS,eAAe,KAAK;AAAA;AAAA,IAC5C;AAEA,gBAAY,UAAU,MAAM,GAAG,EAAE;AACjC;AAAA,MACE;AAAA,MACA,GAAG,SAAS,cAAc;AAAA,EAA2B;AAAA,IACvD;AAAA,EACF;AACF;AAEA,SAAS,eAAe,OAAsB;AAC5C,SAAO,GAAG,MAAM,SAAS,MAAM,QAAQ,KAAK,UAAU,MAAM,MAAM;AACpE;",
  "names": ["path", "data", "chalk"]
}

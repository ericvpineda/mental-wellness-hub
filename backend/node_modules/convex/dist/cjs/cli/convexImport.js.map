{
  "version": 3,
  "sources": ["../../../src/cli/convexImport.ts"],
  "sourcesContent": ["import chalk from \"chalk\";\nimport inquirer from \"inquirer\";\nimport {\n  ensureHasConvexDependency,\n  logAndHandleAxiosError,\n  formatSize,\n  deploymentClient,\n  waitUntilCalled,\n} from \"./lib/utils.js\";\nimport { version } from \"./version.js\";\nimport {\n  logFailure,\n  oneoffContext,\n  Context,\n  showSpinner,\n  logFinishedStep,\n  logWarning,\n  logError,\n  logMessage,\n  stopSpinner,\n  changeSpinner,\n} from \"../bundler/context.js\";\nimport {\n  fetchDeploymentCredentialsProvisionProd,\n  deploymentSelectionFromOptions,\n} from \"./lib/api.js\";\nimport path from \"path\";\nimport { subscribe } from \"./lib/run.js\";\nimport { Command, Option } from \"@commander-js/extra-typings\";\nimport { actionDescription } from \"./lib/command.js\";\n\n// Backend has minimum chunk size of 5MiB except for the last chunk,\n// so we use 5MiB as highWaterMark which makes fs.ReadStream[asyncIterator]\n// output 5MiB chunks before the last one.\nconst CHUNK_SIZE = 5 * 1024 * 1024;\n\nexport const convexImport = new Command(\"import\")\n  .summary(\"Import data from a file to your deployment\")\n  .description(\n    \"Import data from a file to your Convex deployment.\\n\\n\" +\n      \"  From a snapshot: `npx convex import snapshot.zip`\\n\" +\n      \"  For a single table: `npx convex import --table tableName file.json`\\n\\n\" +\n      \"By default, this imports into your dev deployment.\",\n  )\n  .addOption(\n    new Option(\n      \"--table <table>\",\n      \"Destination table name. Required if format is csv, jsonLines, or jsonArray. Not supported if format is zip.\",\n    ),\n  )\n  .addOption(\n    new Option(\n      \"--replace\",\n      \"Replace all existing data in any of the imported tables\",\n    ).conflicts(\"--append\"),\n  )\n  .addOption(\n    new Option(\n      \"--append\",\n      \"Append imported data to any existing tables\",\n    ).conflicts(\"--replace\"),\n  )\n  .option(\n    \"-y, --yes\",\n    \"Skip confirmation prompt when import leads to deleting existing documents\",\n  )\n  .addOption(\n    new Option(\n      \"--format <format>\",\n      \"Input file format. This flag is only required if the filename is missing an extension.\\n\" +\n        \"- CSV files must have a header, and each row's entries are interpreted either as a (floating point) number or a string.\\n\" +\n        \"- JSON files must be an array of JSON objects.\\n\" +\n        \"- JSONLines files must have a JSON object per line.\\n\" +\n        \"- ZIP files must have one directory per table, containing <table>/documents.jsonl. Snapshot exports from the Convex dashboard have this format.\",\n    ).choices([\"csv\", \"jsonLines\", \"jsonArray\", \"zip\"]),\n  )\n  .addDeploymentSelectionOptions(actionDescription(\"Import data into\"))\n  .argument(\"<path>\", \"Path to the input file\")\n  .showHelpAfterError()\n  .action(async (filePath, options, command) => {\n    const ctx = oneoffContext;\n\n    if (command.args.length > 1) {\n      logFailure(\n        ctx,\n        `Error: Too many positional arguments. If you're specifying a table name, use the \\`--table\\` option.`,\n      );\n      return await ctx.crash(1, \"fatal\");\n    }\n\n    const deploymentSelection = deploymentSelectionFromOptions(options);\n\n    const { adminKey, url: deploymentUrl } =\n      await fetchDeploymentCredentialsProvisionProd(ctx, deploymentSelection);\n\n    if (!ctx.fs.exists(filePath)) {\n      logFailure(ctx, `Error: Path ${chalk.bold(filePath)} does not exist.`);\n      return await ctx.crash(1, \"invalid filesystem data\");\n    }\n\n    const format = await determineFormat(ctx, filePath, options.format ?? null);\n    const tableName = options.table ?? null;\n    if (tableName === null) {\n      if (format !== \"zip\") {\n        logFailure(\n          ctx,\n          `Error: The \\`--table\\` option is required for format ${format}`,\n        );\n        return await ctx.crash(1, \"fatal\");\n      }\n    } else {\n      if (format === \"zip\") {\n        logFailure(\n          ctx,\n          `Error: The \\`--table\\` option is not allowed for format ${format}`,\n        );\n        return await ctx.crash(1, \"fatal\");\n      }\n    }\n\n    await ensureHasConvexDependency(ctx, \"import\");\n\n    const data = ctx.fs.createReadStream(filePath, {\n      highWaterMark: CHUNK_SIZE,\n    });\n    const fileStats = ctx.fs.stat(filePath);\n\n    showSpinner(ctx, `Importing ${filePath} (${formatSize(fileStats.size)})`);\n\n    const client = deploymentClient(deploymentUrl);\n    let mode = \"requireEmpty\";\n    if (options.append) {\n      mode = \"append\";\n    } else if (options.replace) {\n      mode = \"replace\";\n    }\n    const importArgs = {\n      tableName: tableName === null ? undefined : tableName,\n      mode,\n      format,\n    };\n    const headers = {\n      Authorization: `Convex ${adminKey}`,\n      \"Convex-Client\": `npm-cli-${version}`,\n    };\n    const deploymentNotice = options.prod\n      ? ` in your ${chalk.bold(\"prod\")} deployment`\n      : \"\";\n    const tableNotice = tableName ? ` to table \"${chalk.bold(tableName)}\"` : \"\";\n    let importId: string;\n    try {\n      const startResp = await client.post(\"/api/import/start_upload\", null, {\n        headers,\n      });\n      const { uploadToken } = startResp.data;\n\n      const partTokens = [];\n      let partNumber = 1;\n\n      for await (const chunk of data) {\n        const partUrl = `/api/import/upload_part?uploadToken=${encodeURIComponent(\n          uploadToken,\n        )}&partNumber=${partNumber}`;\n        const partResp = await client.post(partUrl, chunk, { headers });\n        partTokens.push(partResp.data);\n        partNumber += 1;\n        changeSpinner(\n          ctx,\n          `Uploading ${filePath} (${formatSize(data.bytesRead)}/${formatSize(\n            fileStats.size,\n          )})`,\n        );\n      }\n\n      const finishResp = await client.post(\n        \"/api/import/finish_upload\",\n        {\n          import: importArgs,\n          uploadToken,\n          partTokens,\n        },\n        { headers },\n      );\n      importId = finishResp.data.importId;\n    } catch (e) {\n      logFailure(\n        ctx,\n        `Importing data from \"${chalk.bold(\n          filePath,\n        )}\"${tableNotice}${deploymentNotice} failed`,\n      );\n      return await logAndHandleAxiosError(ctx, e);\n    }\n    changeSpinner(ctx, \"Parsing uploaded data\");\n    // eslint-disable-next-line no-constant-condition\n    while (true) {\n      const snapshotImportState = await waitForStableImportState(\n        ctx,\n        importId,\n        deploymentUrl,\n        adminKey,\n      );\n      switch (snapshotImportState.state) {\n        case \"completed\":\n          logFinishedStep(\n            ctx,\n            `Added ${snapshotImportState.num_rows_written} documents${tableNotice}${deploymentNotice}.`,\n          );\n          return;\n        case \"failed\":\n          logFailure(\n            ctx,\n            `Importing data from \"${chalk.bold(\n              filePath,\n            )}\"${tableNotice}${deploymentNotice} failed`,\n          );\n          logError(ctx, chalk.red(snapshotImportState.error_message));\n          return await ctx.crash(1);\n        case \"waiting_for_confirmation\": {\n          // Clear spinner state so we can log and prompt without clobbering lines.\n          stopSpinner(ctx);\n          await askToConfirmImport(\n            ctx,\n            snapshotImportState.message_to_confirm,\n            snapshotImportState.require_manual_confirmation,\n            options.yes,\n          );\n          showSpinner(ctx, `Importing`);\n          const performUrl = `/api/perform_import`;\n          try {\n            await client.post(performUrl, { importId }, { headers });\n          } catch (e) {\n            logFailure(\n              ctx,\n              `Importing data from \"${chalk.bold(\n                filePath,\n              )}\"${tableNotice}${deploymentNotice} failed`,\n            );\n            return await logAndHandleAxiosError(ctx, e);\n          }\n          // Now we have kicked off the rest of the import, go around the loop again.\n          break;\n        }\n        case \"uploaded\": {\n          logFailure(ctx, `Import canceled while parsing uploaded file`);\n          return await ctx.crash(1);\n        }\n        case \"in_progress\": {\n          logFailure(ctx, `WARNING: Import is continuing to run on the server`);\n          return await ctx.crash(1);\n        }\n        default: {\n          const _: never = snapshotImportState;\n          logFailure(\n            ctx,\n            `unknown error: unexpected state ${snapshotImportState as any}`,\n          );\n          return await ctx.crash(1);\n        }\n      }\n    }\n  });\n\nasync function askToConfirmImport(\n  ctx: Context,\n  messageToConfirm: string | undefined,\n  requireManualConfirmation: boolean | undefined,\n  yes: boolean | undefined,\n) {\n  if (!messageToConfirm?.length) {\n    return;\n  }\n  logMessage(ctx, messageToConfirm);\n  if (requireManualConfirmation !== false && !yes) {\n    const { confirmed } = await inquirer.prompt([\n      {\n        type: \"confirm\",\n        name: \"confirmed\",\n        message: `Perform the import?`,\n        default: true,\n      },\n    ]);\n    if (!confirmed) {\n      return await ctx.crash(1);\n    }\n  }\n}\n\ntype SnapshotImportState =\n  | { state: \"uploaded\" }\n  | {\n      state: \"waiting_for_confirmation\";\n      message_to_confirm?: string;\n      require_manual_confirmation?: boolean;\n    }\n  | {\n      state: \"in_progress\";\n      progress_message?: string | undefined;\n      checkpoint_messages?: string[] | undefined;\n    }\n  | { state: \"completed\"; num_rows_written: bigint }\n  | { state: \"failed\"; error_message: string };\n\nasync function waitForStableImportState(\n  ctx: Context,\n  importId: string,\n  deploymentUrl: string,\n  adminKey: string,\n): Promise<SnapshotImportState> {\n  const [donePromise, onDone] = waitUntilCalled();\n  let snapshotImportState: SnapshotImportState;\n  let checkpointCount = 0;\n  await subscribe(\n    ctx,\n    deploymentUrl,\n    adminKey,\n    \"_system/cli/queryImport\",\n    { importId },\n    donePromise,\n    {\n      onChange: (value: any) => {\n        snapshotImportState = value.state;\n        switch (snapshotImportState.state) {\n          case \"waiting_for_confirmation\":\n          case \"completed\":\n          case \"failed\":\n            onDone();\n            break;\n          case \"uploaded\":\n            // Not a stable state. Ignore while the server continues working.\n            return;\n          case \"in_progress\":\n            // Not a stable state. Ignore while the server continues working.\n            stopSpinner(ctx);\n            while (\n              (snapshotImportState.checkpoint_messages?.length ?? 0) >\n              checkpointCount\n            ) {\n              logFinishedStep(\n                ctx,\n                snapshotImportState.checkpoint_messages![checkpointCount],\n              );\n              checkpointCount += 1;\n            }\n            showSpinner(\n              ctx,\n              snapshotImportState.progress_message ?? \"Importing\",\n            );\n            return;\n        }\n      },\n    },\n  );\n  return snapshotImportState!;\n}\n\nasync function determineFormat(\n  ctx: Context,\n  filePath: string,\n  format: string | null,\n) {\n  const fileExtension = path.extname(filePath);\n  if (fileExtension !== \"\") {\n    const formatToExtension: Record<string, string> = {\n      csv: \".csv\",\n      jsonLines: \".jsonl\",\n      jsonArray: \".json\",\n      zip: \".zip\",\n    };\n    const extensionToFormat = Object.fromEntries(\n      Object.entries(formatToExtension).map((a) => a.reverse()),\n    );\n    if (format !== null && fileExtension !== formatToExtension[format]) {\n      logWarning(\n        ctx,\n        chalk.yellow(\n          `Warning: Extension of file ${filePath} (${fileExtension}) does not match specified format: ${format} (${formatToExtension[format]}).`,\n        ),\n      );\n    }\n    format ??= extensionToFormat[fileExtension] ?? null;\n  }\n  if (format === null) {\n    logFailure(\n      ctx,\n      \"No input file format inferred by the filename extension or specified. Specify your input file's format using the `--format` flag.\",\n    );\n    return await ctx.crash(1, \"fatal\");\n  }\n  return format;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAAkB;AAClB,sBAAqB;AACrB,mBAMO;AACP,qBAAwB;AACxB,qBAWO;AACP,iBAGO;AACP,kBAAiB;AACjB,iBAA0B;AAC1B,2BAAgC;AAChC,qBAAkC;AAKlC,MAAM,aAAa,IAAI,OAAO;AAEvB,MAAM,eAAe,IAAI,6BAAQ,QAAQ,EAC7C,QAAQ,4CAA4C,EACpD;AAAA,EACC;AAIF,EACC;AAAA,EACC,IAAI;AAAA,IACF;AAAA,IACA;AAAA,EACF;AACF,EACC;AAAA,EACC,IAAI;AAAA,IACF;AAAA,IACA;AAAA,EACF,EAAE,UAAU,UAAU;AACxB,EACC;AAAA,EACC,IAAI;AAAA,IACF;AAAA,IACA;AAAA,EACF,EAAE,UAAU,WAAW;AACzB,EACC;AAAA,EACC;AAAA,EACA;AACF,EACC;AAAA,EACC,IAAI;AAAA,IACF;AAAA,IACA;AAAA,EAKF,EAAE,QAAQ,CAAC,OAAO,aAAa,aAAa,KAAK,CAAC;AACpD,EACC,kCAA8B,kCAAkB,kBAAkB,CAAC,EACnE,SAAS,UAAU,wBAAwB,EAC3C,mBAAmB,EACnB,OAAO,OAAO,UAAU,SAAS,YAAY;AAC5C,QAAM,MAAM;AAEZ,MAAI,QAAQ,KAAK,SAAS,GAAG;AAC3B;AAAA,MACE;AAAA,MACA;AAAA,IACF;AACA,WAAO,MAAM,IAAI,MAAM,GAAG,OAAO;AAAA,EACnC;AAEA,QAAM,0BAAsB,2CAA+B,OAAO;AAElE,QAAM,EAAE,UAAU,KAAK,cAAc,IACnC,UAAM,oDAAwC,KAAK,mBAAmB;AAExE,MAAI,CAAC,IAAI,GAAG,OAAO,QAAQ,GAAG;AAC5B,mCAAW,KAAK,eAAe,aAAAA,QAAM,KAAK,QAAQ,mBAAmB;AACrE,WAAO,MAAM,IAAI,MAAM,GAAG,yBAAyB;AAAA,EACrD;AAEA,QAAM,SAAS,MAAM,gBAAgB,KAAK,UAAU,QAAQ,UAAU,IAAI;AAC1E,QAAM,YAAY,QAAQ,SAAS;AACnC,MAAI,cAAc,MAAM;AACtB,QAAI,WAAW,OAAO;AACpB;AAAA,QACE;AAAA,QACA,wDAAwD;AAAA,MAC1D;AACA,aAAO,MAAM,IAAI,MAAM,GAAG,OAAO;AAAA,IACnC;AAAA,EACF,OAAO;AACL,QAAI,WAAW,OAAO;AACpB;AAAA,QACE;AAAA,QACA,2DAA2D;AAAA,MAC7D;AACA,aAAO,MAAM,IAAI,MAAM,GAAG,OAAO;AAAA,IACnC;AAAA,EACF;AAEA,YAAM,wCAA0B,KAAK,QAAQ;AAE7C,QAAM,OAAO,IAAI,GAAG,iBAAiB,UAAU;AAAA,IAC7C,eAAe;AAAA,EACjB,CAAC;AACD,QAAM,YAAY,IAAI,GAAG,KAAK,QAAQ;AAEtC,kCAAY,KAAK,aAAa,iBAAa,yBAAW,UAAU,IAAI,IAAI;AAExE,QAAM,aAAS,+BAAiB,aAAa;AAC7C,MAAI,OAAO;AACX,MAAI,QAAQ,QAAQ;AAClB,WAAO;AAAA,EACT,WAAW,QAAQ,SAAS;AAC1B,WAAO;AAAA,EACT;AACA,QAAM,aAAa;AAAA,IACjB,WAAW,cAAc,OAAO,SAAY;AAAA,IAC5C;AAAA,IACA;AAAA,EACF;AACA,QAAM,UAAU;AAAA,IACd,eAAe,UAAU;AAAA,IACzB,iBAAiB,WAAW;AAAA,EAC9B;AACA,QAAM,mBAAmB,QAAQ,OAC7B,YAAY,aAAAA,QAAM,KAAK,MAAM,iBAC7B;AACJ,QAAM,cAAc,YAAY,cAAc,aAAAA,QAAM,KAAK,SAAS,OAAO;AACzE,MAAI;AACJ,MAAI;AACF,UAAM,YAAY,MAAM,OAAO,KAAK,4BAA4B,MAAM;AAAA,MACpE;AAAA,IACF,CAAC;AACD,UAAM,EAAE,YAAY,IAAI,UAAU;AAElC,UAAM,aAAa,CAAC;AACpB,QAAI,aAAa;AAEjB,qBAAiB,SAAS,MAAM;AAC9B,YAAM,UAAU,uCAAuC;AAAA,QACrD;AAAA,MACF,gBAAgB;AAChB,YAAM,WAAW,MAAM,OAAO,KAAK,SAAS,OAAO,EAAE,QAAQ,CAAC;AAC9D,iBAAW,KAAK,SAAS,IAAI;AAC7B,oBAAc;AACd;AAAA,QACE;AAAA,QACA,aAAa,iBAAa,yBAAW,KAAK,SAAS,SAAK;AAAA,UACtD,UAAU;AAAA,QACZ;AAAA,MACF;AAAA,IACF;AAEA,UAAM,aAAa,MAAM,OAAO;AAAA,MAC9B;AAAA,MACA;AAAA,QACE,QAAQ;AAAA,QACR;AAAA,QACA;AAAA,MACF;AAAA,MACA,EAAE,QAAQ;AAAA,IACZ;AACA,eAAW,WAAW,KAAK;AAAA,EAC7B,SAAS,GAAP;AACA;AAAA,MACE;AAAA,MACA,wBAAwB,aAAAA,QAAM;AAAA,QAC5B;AAAA,MACF,KAAK,cAAc;AAAA,IACrB;AACA,WAAO,UAAM,qCAAuB,KAAK,CAAC;AAAA,EAC5C;AACA,oCAAc,KAAK,uBAAuB;AAE1C,SAAO,MAAM;AACX,UAAM,sBAAsB,MAAM;AAAA,MAChC;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AACA,YAAQ,oBAAoB,OAAO;AAAA,MACjC,KAAK;AACH;AAAA,UACE;AAAA,UACA,SAAS,oBAAoB,6BAA6B,cAAc;AAAA,QAC1E;AACA;AAAA,MACF,KAAK;AACH;AAAA,UACE;AAAA,UACA,wBAAwB,aAAAA,QAAM;AAAA,YAC5B;AAAA,UACF,KAAK,cAAc;AAAA,QACrB;AACA,qCAAS,KAAK,aAAAA,QAAM,IAAI,oBAAoB,aAAa,CAAC;AAC1D,eAAO,MAAM,IAAI,MAAM,CAAC;AAAA,MAC1B,KAAK,4BAA4B;AAE/B,wCAAY,GAAG;AACf,cAAM;AAAA,UACJ;AAAA,UACA,oBAAoB;AAAA,UACpB,oBAAoB;AAAA,UACpB,QAAQ;AAAA,QACV;AACA,wCAAY,KAAK,WAAW;AAC5B,cAAM,aAAa;AACnB,YAAI;AACF,gBAAM,OAAO,KAAK,YAAY,EAAE,SAAS,GAAG,EAAE,QAAQ,CAAC;AAAA,QACzD,SAAS,GAAP;AACA;AAAA,YACE;AAAA,YACA,wBAAwB,aAAAA,QAAM;AAAA,cAC5B;AAAA,YACF,KAAK,cAAc;AAAA,UACrB;AACA,iBAAO,UAAM,qCAAuB,KAAK,CAAC;AAAA,QAC5C;AAEA;AAAA,MACF;AAAA,MACA,KAAK,YAAY;AACf,uCAAW,KAAK,6CAA6C;AAC7D,eAAO,MAAM,IAAI,MAAM,CAAC;AAAA,MAC1B;AAAA,MACA,KAAK,eAAe;AAClB,uCAAW,KAAK,oDAAoD;AACpE,eAAO,MAAM,IAAI,MAAM,CAAC;AAAA,MAC1B;AAAA,MACA,SAAS;AACP,cAAM,IAAW;AACjB;AAAA,UACE;AAAA,UACA,mCAAmC;AAAA,QACrC;AACA,eAAO,MAAM,IAAI,MAAM,CAAC;AAAA,MAC1B;AAAA,IACF;AAAA,EACF;AACF,CAAC;AAEH,eAAe,mBACb,KACA,kBACA,2BACA,KACA;AACA,MAAI,CAAC,kBAAkB,QAAQ;AAC7B;AAAA,EACF;AACA,iCAAW,KAAK,gBAAgB;AAChC,MAAI,8BAA8B,SAAS,CAAC,KAAK;AAC/C,UAAM,EAAE,UAAU,IAAI,MAAM,gBAAAC,QAAS,OAAO;AAAA,MAC1C;AAAA,QACE,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS;AAAA,QACT,SAAS;AAAA,MACX;AAAA,IACF,CAAC;AACD,QAAI,CAAC,WAAW;AACd,aAAO,MAAM,IAAI,MAAM,CAAC;AAAA,IAC1B;AAAA,EACF;AACF;AAiBA,eAAe,yBACb,KACA,UACA,eACA,UAC8B;AAC9B,QAAM,CAAC,aAAa,MAAM,QAAI,8BAAgB;AAC9C,MAAI;AACJ,MAAI,kBAAkB;AACtB,YAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,EAAE,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,UAAU,CAAC,UAAe;AACxB,8BAAsB,MAAM;AAC5B,gBAAQ,oBAAoB,OAAO;AAAA,UACjC,KAAK;AAAA,UACL,KAAK;AAAA,UACL,KAAK;AACH,mBAAO;AACP;AAAA,UACF,KAAK;AAEH;AAAA,UACF,KAAK;AAEH,4CAAY,GAAG;AACf,oBACG,oBAAoB,qBAAqB,UAAU,KACpD,iBACA;AACA;AAAA,gBACE;AAAA,gBACA,oBAAoB,oBAAqB,eAAe;AAAA,cAC1D;AACA,iCAAmB;AAAA,YACrB;AACA;AAAA,cACE;AAAA,cACA,oBAAoB,oBAAoB;AAAA,YAC1C;AACA;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACA,SAAO;AACT;AAEA,eAAe,gBACb,KACA,UACA,QACA;AACA,QAAM,gBAAgB,YAAAC,QAAK,QAAQ,QAAQ;AAC3C,MAAI,kBAAkB,IAAI;AACxB,UAAM,oBAA4C;AAAA,MAChD,KAAK;AAAA,MACL,WAAW;AAAA,MACX,WAAW;AAAA,MACX,KAAK;AAAA,IACP;AACA,UAAM,oBAAoB,OAAO;AAAA,MAC/B,OAAO,QAAQ,iBAAiB,EAAE,IAAI,CAAC,MAAM,EAAE,QAAQ,CAAC;AAAA,IAC1D;AACA,QAAI,WAAW,QAAQ,kBAAkB,kBAAkB,MAAM,GAAG;AAClE;AAAA,QACE;AAAA,QACA,aAAAF,QAAM;AAAA,UACJ,8BAA8B,aAAa,mDAAmD,WAAW,kBAAkB,MAAM;AAAA,QACnI;AAAA,MACF;AAAA,IACF;AACA,wBAAW,kBAAkB,aAAa,KAAK;AAAA,EACjD;AACA,MAAI,WAAW,MAAM;AACnB;AAAA,MACE;AAAA,MACA;AAAA,IACF;AACA,WAAO,MAAM,IAAI,MAAM,GAAG,OAAO;AAAA,EACnC;AACA,SAAO;AACT;",
  "names": ["chalk", "inquirer", "path"]
}
